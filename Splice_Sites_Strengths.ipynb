{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from Bio import SeqIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Chromosome    Start      End             Region Score Strand      Type  \\\n",
      "0          1  1211697  1211706  1:1211625-1211703     0      -     donor   \n",
      "1          1  1211622  1211645  1:1211625-1211703     0      -  acceptor   \n",
      "2          1  1211935  1211944  1:1211832-1211941     0      -     donor   \n",
      "3          1  1211829  1211852  1:1211832-1211941     0      -  acceptor   \n",
      "4          1  1212631  1212640  1:1212138-1212637     0      -     donor   \n",
      "\n",
      "        Transcript             Gene  \n",
      "0  ENST00000379236  ENSG00000186827  \n",
      "1  ENST00000379236  ENSG00000186827  \n",
      "2  ENST00000379236  ENSG00000186827  \n",
      "3  ENST00000379236  ENSG00000186827  \n",
      "4  ENST00000379236  ENSG00000186827  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Reading files\n",
    "splicing_file = 'splice_regions.bed'\n",
    "genome_file = 'Homo_sapiens.GRCh38.dna.primary_assembly.fa'\n",
    "significant_genes_file = 'unique_gene_ids.csv'\n",
    "\n",
    "\n",
    "# Load the files\n",
    "significant_genes = pd.read_csv(significant_genes_file)\n",
    "genome = SeqIO.to_dict(SeqIO.parse(genome_file, 'fasta'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define column names for the BED file\n",
    "column_names = ['Chromosome', 'Start', 'End', 'Region', 'Score', 'Strand', 'Type', 'Transcript', 'Gene']\n",
    "\n",
    "\n",
    "# Read the BED file with headers\n",
    "bed_data = pd.read_csv(splicing_file, sep='\\t', header=None, names=column_names, dtype=str)\n",
    "bed_data['Chromosome'] = bed_data['Chromosome'].astype(str)\n",
    "# Display the first few rows of the dataframe with headers\n",
    "print(bed_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Chromosome     Start       End                Region Score Strand  \\\n",
      "0                1   1211697   1211706     1:1211625-1211703     0      -   \n",
      "1                1   1211622   1211645     1:1211625-1211703     0      -   \n",
      "2                1   1211935   1211944     1:1211832-1211941     0      -   \n",
      "3                1   1211829   1211852     1:1211832-1211941     0      -   \n",
      "4                1   1212631   1212640     1:1212138-1212637     0      -   \n",
      "...            ...       ...       ...                   ...   ...    ...   \n",
      "2522493         21  31464032  31464055  21:31464035-31558926     0      -   \n",
      "2522495         21  31118667  31118690  21:31118670-31124521     0      -   \n",
      "2522522         21  31160438  31160447  21:31154426-31160444     0      -   \n",
      "2522542         21  31559912  31559921  21:31464035-31559918     0      -   \n",
      "2522548         21  31344131  31344140  21:31339422-31344137     0      -   \n",
      "\n",
      "             Type       Transcript             Gene  \n",
      "0           donor  ENST00000379236  ENSG00000186827  \n",
      "1        acceptor  ENST00000379236  ENSG00000186827  \n",
      "2           donor  ENST00000379236  ENSG00000186827  \n",
      "3        acceptor  ENST00000379236  ENSG00000186827  \n",
      "4           donor  ENST00000379236  ENSG00000186827  \n",
      "...           ...              ...              ...  \n",
      "2522493  acceptor  ENST00000286827  ENSG00000156299  \n",
      "2522495  acceptor  ENST00000423206  ENSG00000156299  \n",
      "2522522     donor  ENST00000636887  ENSG00000156299  \n",
      "2522542     donor  ENST00000469412  ENSG00000156299  \n",
      "2522548     donor  ENST00000455508  ENSG00000156299  \n",
      "\n",
      "[607940 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# Filtering the data to include only the unique of splice sites\n",
    "unique_splice_sites = bed_data.drop_duplicates(subset=['Chromosome', 'Start', 'End', 'Strand', 'Type'])\n",
    "\n",
    "\n",
    "# Display the DataFrame to verify\n",
    "print(unique_splice_sites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Chromosome    Start      End             Region Score Strand      Type  \\\n",
      "0           1  1211697  1211706  1:1211625-1211703     0      -     donor   \n",
      "1           1  1211622  1211645  1:1211625-1211703     0      -  acceptor   \n",
      "2           1  1211935  1211944  1:1211832-1211941     0      -     donor   \n",
      "3           1  1211829  1211852  1:1211832-1211941     0      -  acceptor   \n",
      "4           1  1212631  1212640  1:1212138-1212637     0      -     donor   \n",
      "5           1  1212135  1212158  1:1212138-1212637     0      -  acceptor   \n",
      "6           1  1212985  1212994  1:1212704-1212991     0      -     donor   \n",
      "7           1  1212701  1212724  1:1212704-1212991     0      -  acceptor   \n",
      "8           1  1213656  1213665  1:1213093-1213662     0      -     donor   \n",
      "9           1  1213090  1213113  1:1213093-1213662     0      -  acceptor   \n",
      "10          1  1213976  1213985  1:1213785-1213982     0      -     donor   \n",
      "11          1  1213782  1213805  1:1213785-1213982     0      -  acceptor   \n",
      "12          1  1211935  1211944  1:1211832-1211941     0      -     donor   \n",
      "13          1  1211829  1211852  1:1211832-1211941     0      -  acceptor   \n",
      "14          1  1212631  1212640  1:1212138-1212637     0      -     donor   \n",
      "15          1  1212135  1212158  1:1212138-1212637     0      -  acceptor   \n",
      "16          1  1212985  1212994  1:1212704-1212991     0      -     donor   \n",
      "17          1  1212701  1212724  1:1212704-1212991     0      -  acceptor   \n",
      "18          1  1213976  1213985  1:1213785-1213982     0      -     donor   \n",
      "19          1  1213782  1213805  1:1213785-1213982     0      -  acceptor   \n",
      "20          1  1212631  1212640  1:1212138-1212637     0      -     donor   \n",
      "21          1  1212135  1212158  1:1212138-1212637     0      -  acceptor   \n",
      "22          1  1212985  1212994  1:1212704-1212991     0      -     donor   \n",
      "23          1  1212701  1212724  1:1212704-1212991     0      -  acceptor   \n",
      "24          1  1213388  1213397  1:1213093-1213394     0      -     donor   \n",
      "25          1  1213090  1213113  1:1213093-1213394     0      -  acceptor   \n",
      "\n",
      "         Transcript             Gene  \n",
      "0   ENST00000379236  ENSG00000186827  \n",
      "1   ENST00000379236  ENSG00000186827  \n",
      "2   ENST00000379236  ENSG00000186827  \n",
      "3   ENST00000379236  ENSG00000186827  \n",
      "4   ENST00000379236  ENSG00000186827  \n",
      "5   ENST00000379236  ENSG00000186827  \n",
      "6   ENST00000379236  ENSG00000186827  \n",
      "7   ENST00000379236  ENSG00000186827  \n",
      "8   ENST00000379236  ENSG00000186827  \n",
      "9   ENST00000379236  ENSG00000186827  \n",
      "10  ENST00000379236  ENSG00000186827  \n",
      "11  ENST00000379236  ENSG00000186827  \n",
      "12  ENST00000497869  ENSG00000186827  \n",
      "13  ENST00000497869  ENSG00000186827  \n",
      "14  ENST00000497869  ENSG00000186827  \n",
      "15  ENST00000497869  ENSG00000186827  \n",
      "16  ENST00000497869  ENSG00000186827  \n",
      "17  ENST00000497869  ENSG00000186827  \n",
      "18  ENST00000497869  ENSG00000186827  \n",
      "19  ENST00000497869  ENSG00000186827  \n",
      "20  ENST00000453580  ENSG00000186827  \n",
      "21  ENST00000453580  ENSG00000186827  \n",
      "22  ENST00000453580  ENSG00000186827  \n",
      "23  ENST00000453580  ENSG00000186827  \n",
      "24  ENST00000453580  ENSG00000186827  \n",
      "25  ENST00000453580  ENSG00000186827  \n"
     ]
    }
   ],
   "source": [
    "# testing on gene ENSG00000186827  \n",
    "\n",
    "test_data = bed_data[bed_data['Gene'] == 'ENSG00000186827']\n",
    "\n",
    "# Print the filtered rows\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Chromosome    Start      End             Region Score Strand      Type  \\\n",
      "0           1  1211697  1211706  1:1211625-1211703     0      -     donor   \n",
      "1           1  1211622  1211645  1:1211625-1211703     0      -  acceptor   \n",
      "2           1  1211935  1211944  1:1211832-1211941     0      -     donor   \n",
      "3           1  1211829  1211852  1:1211832-1211941     0      -  acceptor   \n",
      "4           1  1212631  1212640  1:1212138-1212637     0      -     donor   \n",
      "5           1  1212135  1212158  1:1212138-1212637     0      -  acceptor   \n",
      "6           1  1212985  1212994  1:1212704-1212991     0      -     donor   \n",
      "7           1  1212701  1212724  1:1212704-1212991     0      -  acceptor   \n",
      "8           1  1213656  1213665  1:1213093-1213662     0      -     donor   \n",
      "9           1  1213090  1213113  1:1213093-1213662     0      -  acceptor   \n",
      "10          1  1213976  1213985  1:1213785-1213982     0      -     donor   \n",
      "11          1  1213782  1213805  1:1213785-1213982     0      -  acceptor   \n",
      "24          1  1213388  1213397  1:1213093-1213394     0      -     donor   \n",
      "\n",
      "         Transcript             Gene  \n",
      "0   ENST00000379236  ENSG00000186827  \n",
      "1   ENST00000379236  ENSG00000186827  \n",
      "2   ENST00000379236  ENSG00000186827  \n",
      "3   ENST00000379236  ENSG00000186827  \n",
      "4   ENST00000379236  ENSG00000186827  \n",
      "5   ENST00000379236  ENSG00000186827  \n",
      "6   ENST00000379236  ENSG00000186827  \n",
      "7   ENST00000379236  ENSG00000186827  \n",
      "8   ENST00000379236  ENSG00000186827  \n",
      "9   ENST00000379236  ENSG00000186827  \n",
      "10  ENST00000379236  ENSG00000186827  \n",
      "11  ENST00000379236  ENSG00000186827  \n",
      "24  ENST00000453580  ENSG00000186827  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RTX 3070 TI\\AppData\\Local\\Temp\\ipykernel_16608\\2748475941.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  test_data2 = unique_splice_sites[bed_data['Gene'] == 'ENSG00000186827']\n"
     ]
    }
   ],
   "source": [
    "# now we check the unique splice sites of gene ENSG00000186827\n",
    "test_data2 = unique_splice_sites[bed_data['Gene'] == 'ENSG00000186827']\n",
    "\n",
    "\n",
    "print(test_data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to sequence\n",
    "def get_sequence(chromosome, start, end, strand):\n",
    "    sequence = genome[chromosome].seq[start:end]\n",
    "    if strand == '-':\n",
    "        sequence = sequence.reverse_complement()\n",
    "    return str(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to extract the 5 prime sequences\n",
    "def extract_5_prime_sequences(gene_id):\n",
    "    sequences = []\n",
    "    gene_splice_sites = unique_splice_sites[(unique_splice_sites['Gene'] == gene_id) & (unique_splice_sites['Type'] == 'donor')]\n",
    "    for idx, row in gene_splice_sites.iterrows():\n",
    "        sequence = get_sequence(row['Chromosome'], int(row['Start']), int(row['End']), row['Strand'])\n",
    "        sequences.append(sequence)\n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_5_prime_sequences = []\n",
    "\n",
    "for gene_id in significant_genes['GeneID']:\n",
    "    try:\n",
    "        sequences = extract_5_prime_sequences(gene_id)\n",
    "        all_5_prime_sequences.extend(sequences)  # Only add the sequences\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {gene_id}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame\n",
    "sequences_df = pd.DataFrame(all_5_prime_sequences, columns=['sequence'])\n",
    "\n",
    "# Save to TXT\n",
    "sequences_df.to_csv('5_prime_sequences_Significant.txt', index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to extract the 3 prime sequences\n",
    "def extract_3_prime_sequences(gene_id):\n",
    "    sequences = []\n",
    "    gene_splice_sites = unique_splice_sites[(unique_splice_sites['Gene'] == gene_id) & (unique_splice_sites['Type'] == 'acceptor')]\n",
    "    for idx, row in gene_splice_sites.iterrows():\n",
    "        sequence = get_sequence(row['Chromosome'], int(row['Start']), int(row['End']), row['Strand'])\n",
    "        sequences.append(sequence)\n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_3_prime_sequences = []\n",
    "\n",
    "for gene_id in significant_genes['GeneID']:\n",
    "    try:\n",
    "        sequences = extract_3_prime_sequences(gene_id)\n",
    "        all_3_prime_sequences.extend(sequences)  # Only add the sequences\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {gene_id}: {e}\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "sequences_df = pd.DataFrame(all_3_prime_sequences, columns=['sequence'])\n",
    "\n",
    "# Save to TXT\n",
    "sequences_df.to_csv('3_prime_sequences_Significant.txt', index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 3' and 5' splice site sequences are analyzed for splice site strength using the following two websites.\n",
    "# http://hollywood.mit.edu/burgelab/maxent/Xmaxentscan_scoreseq.html\n",
    "# http://hollywood.mit.edu/burgelab/maxent/Xmaxentscan_scoreseq_acc.html\n",
    "# the results are saved in 3_prime_sequences_Significant.txt and 5_prime_sequences_Significant.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We extract the values from both files, and then we combine them into one file so we can compare them to the unaffected genes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Read the prime 5 file content\n",
    "with open('5_prime_sequences_Significant.txt', 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Use regular expression to find all MAXENT values\n",
    "pattern = r'MAXENT:\\s*(-?\\d*\\.?\\d+)'\n",
    "\n",
    "values = re.findall(pattern, content)\n",
    "\n",
    "\n",
    "# Convert values to float \n",
    "values = [float(value) for value in values]\n",
    "\n",
    "with open('SSS_5significantGenes.txt', 'w') as output_file:\n",
    "    for value in values:\n",
    "        output_file.write(f'{value}\\n')\n",
    "\n",
    "# SSS = Splice Site Strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the prime 3 file content\n",
    "with open('3_prime_sequences_Significant.txt', 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Use regular expression to find all MAXENT values\n",
    "pattern = r'MAXENT:\\s*(-?\\d*\\.?\\d+)'\n",
    "\n",
    "values = re.findall(pattern, content)\n",
    "\n",
    "\n",
    "# Convert values to float \n",
    "values = [float(value) for value in values]\n",
    "\n",
    "with open('SSS_3significantGenes.txt', 'w') as output_file:\n",
    "    for value in values:\n",
    "        output_file.write(f'{value}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the two files\n",
    "file1 = 'SSS_3significantGenes.txt'\n",
    "file2 = 'SSS_5significantGenes.txt'\n",
    "combined_file = 'SSS_significantGenes.txt'\n",
    "\n",
    "# Open the files in read mode\n",
    "with open(file1, 'r') as f1, open(file2, 'r') as f2:\n",
    "    # Read the contents of the files\n",
    "    file1_contents = f1.readlines()\n",
    "    file2_contents = f2.readlines()\n",
    "\n",
    "# Open the combined file in write mode\n",
    "with open(combined_file, 'w') as f_combined:\n",
    "    # Write the contents of the first file\n",
    "    f_combined.writelines(file1_contents)\n",
    "    # Write the contents of the second file\n",
    "    f_combined.writelines(file2_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The same process is done for the unaffected genes\n",
    "\n",
    "unaffected_genes_file = 'Unaffected_Genes.csv'\n",
    "\n",
    "# Load the files\n",
    "unaffected_genes = pd.read_csv(unaffected_genes_file)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting the 5 prime splice sites sequences of the unaffected genes\n",
    "\n",
    "all_5_prime_sequences = []\n",
    "\n",
    "for gene_id in unaffected_genes['GeneID']:\n",
    "    try:\n",
    "        sequences = extract_5_prime_sequences(gene_id)\n",
    "        all_5_prime_sequences.extend(sequences)  # Only add the sequences\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {gene_id}: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "# Convert to DataFrame\n",
    "sequences_df = pd.DataFrame(all_5_prime_sequences, columns=['sequence'])\n",
    "\n",
    "# Save to TXT\n",
    "sequences_df.to_csv('5_prime_sequences_Unaffected.txt', index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_3_prime_sequences = []\n",
    "\n",
    "for gene_id in unaffected_genes['GeneID']:\n",
    "    try:\n",
    "        sequences = extract_3_prime_sequences(gene_id)\n",
    "        all_3_prime_sequences.extend(sequences)  # Only add the sequences\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {gene_id}: {e}\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "sequences_df = pd.DataFrame(all_3_prime_sequences, columns=['sequence'])\n",
    "\n",
    "# Save to TXT\n",
    "sequences_df.to_csv('3_prime_sequences_Unaffected.txt', index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 3' and 5' splice site sequences are analyzed for splice site strength using the following two websites.\n",
    "# http://hollywood.mit.edu/burgelab/maxent/Xmaxentscan_scoreseq.html\n",
    "# http://hollywood.mit.edu/burgelab/maxent/Xmaxentscan_scoreseq_acc.html\n",
    "# the results are saved in 3_prime_sequences_Unaffected.txt and 5_prime_sequences_Unaffected.txt\n",
    "# We extract the values from both files, and then we combine them into one file so we can compare them to the significant genes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the prime 5 file content\n",
    "with open('5_prime_sequences_Unaffected.txt', 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Use regular expression to find all MAXENT values\n",
    "pattern = r'MAXENT:\\s*(-?\\d*\\.?\\d+)'\n",
    "\n",
    "values = re.findall(pattern, content)\n",
    "\n",
    "\n",
    "# Convert values to float \n",
    "values = [float(value) for value in values]\n",
    "\n",
    "with open('SSS_5UnaffectedGenes.txt', 'w') as output_file:\n",
    "    for value in values:\n",
    "        output_file.write(f'{value}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the prime 3 file content\n",
    "with open('3_prime_sequences_Unaffected.txt', 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Use regular expression to find all MAXENT values\n",
    "pattern = r'MAXENT:\\s*(-?\\d*\\.?\\d+)'\n",
    "\n",
    "values = re.findall(pattern, content)\n",
    "\n",
    "\n",
    "# Convert values to float \n",
    "values = [float(value) for value in values]\n",
    "\n",
    "with open('SSS_3UnaffectedGenes.txt', 'w') as output_file:\n",
    "    for value in values:\n",
    "        output_file.write(f'{value}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the two files\n",
    "file1 = 'SSS_3UnaffectedGenes.txt'\n",
    "file2 = 'SSS_5UnaffectedGenes.txt'\n",
    "combined_file = 'SSS_UnaffectedGenes.txt'\n",
    "\n",
    "# Open the files in read mode\n",
    "with open(file1, 'r') as f1, open(file2, 'r') as f2:\n",
    "    # Read the contents of the files\n",
    "    file1_contents = f1.readlines()\n",
    "    file2_contents = f2.readlines()\n",
    "\n",
    "# Open the combined file in write mode\n",
    "with open(combined_file, 'w') as f_combined:\n",
    "    # Write the contents of the first file\n",
    "    f_combined.writelines(file1_contents)\n",
    "    # Write the contents of the second file\n",
    "    f_combined.writelines(file2_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we calculate the splice sites strength based on the different alternative splicing events of the significant genes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skipped exon alternative splicing.\n",
    "\n",
    "unique_genes = pd.read_csv('SkippedExon_Genes.txt', header=None, names=['GeneID'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#extracting the 5 prime splice sites sequences \n",
    "all_5_prime_sequences = []\n",
    "\n",
    "for gene_id in unique_genes['GeneID']:\n",
    "    try:\n",
    "        sequences = extract_5_prime_sequences(gene_id)\n",
    "        all_5_prime_sequences.extend(sequences)  # Only add the sequences\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {gene_id}: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "# Convert to DataFrame\n",
    "sequences_df = pd.DataFrame(all_5_prime_sequences, columns=['sequence'])\n",
    "\n",
    "# Save to TXT\n",
    "sequences_df.to_csv('5_prime_SKippedExons.txt', index=False, sep='\\t')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#extracting the 3 prime splice sites sequences\n",
    "all_3_prime_sequences = []\n",
    "\n",
    "for gene_id in unique_genes['GeneID']:\n",
    "    try:\n",
    "        sequences = extract_3_prime_sequences(gene_id)\n",
    "        all_3_prime_sequences.extend(sequences)  # Only add the sequences\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {gene_id}: {e}\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "sequences_df = pd.DataFrame(all_3_prime_sequences, columns=['sequence'])\n",
    "\n",
    "# Save to TXT\n",
    "sequences_df.to_csv('3_prime_SkippedExons.txt', index=False, sep='\\t')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# The 3' and 5' splice site sequences are analyzed for splice site strength using the following two websites.\n",
    "# http://hollywood.mit.edu/burgelab/maxent/Xmaxentscan_scoreseq.html\n",
    "# http://hollywood.mit.edu/burgelab/maxent/Xmaxentscan_scoreseq_acc.html\n",
    "# the results are saved in 5_prime_SKippedExons.txt and 3_prime_SKippedExons.txt\n",
    "# We extract the values from both files, and then we combine them into one file \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the prime 5 file content\n",
    "with open('5_prime_SKippedExons.txt', 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Use regular expression to find all MAXENT values\n",
    "pattern = r'MAXENT:\\s*(-?\\d*\\.?\\d+)'\n",
    "\n",
    "values = re.findall(pattern, content)\n",
    "\n",
    "\n",
    "# Convert values to float \n",
    "values = [float(value) for value in values]\n",
    "\n",
    "with open('SSS_5SkippedExons.txt', 'w') as output_file:\n",
    "    for value in values:\n",
    "        output_file.write(f'{value}\\n')\n",
    "\n",
    "\n",
    "# Read the prime 3 file content\n",
    "with open('3_prime_SKippedExons.txt', 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Use regular expression to find all MAXENT values\n",
    "pattern = r'MAXENT:\\s*(-?\\d*\\.?\\d+)'\n",
    "\n",
    "values = re.findall(pattern, content)\n",
    "\n",
    "\n",
    "# Convert values to float \n",
    "values = [float(value) for value in values]\n",
    "\n",
    "with open('SSS_3SkippedExons.txt', 'w') as output_file:\n",
    "    for value in values:\n",
    "        output_file.write(f'{value}\\n')\n",
    "\n",
    "\n",
    "\n",
    "# combine the two files\n",
    "file1 = 'SSS_5SkippedExons.txt'\n",
    "file2 = 'SSS_3SkippedExons.txt'\n",
    "combined_file = 'SSS_SkippedExons.txt'\n",
    "\n",
    "# Open the files in read mode\n",
    "with open(file1, 'r') as f1, open(file2, 'r') as f2:\n",
    "    # Read the contents of the files\n",
    "    file1_contents = f1.readlines()\n",
    "    file2_contents = f2.readlines()\n",
    "\n",
    "# Open the combined file in write mode\n",
    "with open(combined_file, 'w') as f_combined:\n",
    "    # Write the contents of the first file\n",
    "    f_combined.writelines(file1_contents)\n",
    "    # Write the contents of the second file\n",
    "    f_combined.writelines(file2_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mutually Exclusive alternative splicing.\n",
    "\n",
    "unique_genes = pd.read_csv('MutuallyExclusive_Genes.txt', header=None, names=['GeneID'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#extracting the 5 prime splice sites sequences \n",
    "all_5_prime_sequences = []\n",
    "\n",
    "for gene_id in unique_genes['GeneID']:\n",
    "    try:\n",
    "        sequences = extract_5_prime_sequences(gene_id)\n",
    "        all_5_prime_sequences.extend(sequences)  # Only add the sequences\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {gene_id}: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "# Convert to DataFrame\n",
    "sequences_df = pd.DataFrame(all_5_prime_sequences, columns=['sequence'])\n",
    "\n",
    "# Save to TXT\n",
    "sequences_df.to_csv('5_prime_MutuallyExclusive.txt', index=False, sep='\\t')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#extracting the 3 prime splice sites sequences\n",
    "all_3_prime_sequences = []\n",
    "\n",
    "for gene_id in unique_genes['GeneID']:\n",
    "    try:\n",
    "        sequences = extract_3_prime_sequences(gene_id)\n",
    "        all_3_prime_sequences.extend(sequences)  # Only add the sequences\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {gene_id}: {e}\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "sequences_df = pd.DataFrame(all_3_prime_sequences, columns=['sequence'])\n",
    "\n",
    "# Save to TXT\n",
    "sequences_df.to_csv('3_prime_MutuallyExclusive.txt', index=False, sep='\\t')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# The 3' and 5' splice site sequences are analyzed for splice site strength using the following two websites.\n",
    "# http://hollywood.mit.edu/burgelab/maxent/Xmaxentscan_scoreseq.html\n",
    "# http://hollywood.mit.edu/burgelab/maxent/Xmaxentscan_scoreseq_acc.html\n",
    "# the results are saved in 3_prime_MutuallyExclusive.txt and 5_prime_MutuallyExclusive.txt\n",
    "# We extract the values from both files, and then we combine them into one file \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the prime 5 file content\n",
    "with open('5_prime_MutuallyExclusive.txt', 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Use regular expression to find all MAXENT values\n",
    "pattern = r'MAXENT:\\s*(-?\\d*\\.?\\d+)'\n",
    "\n",
    "values = re.findall(pattern, content)\n",
    "\n",
    "\n",
    "# Convert values to float \n",
    "values = [float(value) for value in values]\n",
    "\n",
    "with open('SSS_5MutuallyExclusive.txt', 'w') as output_file:\n",
    "    for value in values:\n",
    "        output_file.write(f'{value}\\n')\n",
    "\n",
    "\n",
    "# Read the prime 3 file content\n",
    "with open('3_prime_MutuallyExclusive.txt', 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Use regular expression to find all MAXENT values\n",
    "pattern = r'MAXENT:\\s*(-?\\d*\\.?\\d+)'\n",
    "\n",
    "values = re.findall(pattern, content)\n",
    "\n",
    "\n",
    "# Convert values to float \n",
    "values = [float(value) for value in values]\n",
    "\n",
    "with open('SSS_3MutuallyExclusive.txt', 'w') as output_file:\n",
    "    for value in values:\n",
    "        output_file.write(f'{value}\\n')\n",
    "\n",
    "\n",
    "\n",
    "# combine the two files\n",
    "file1 = 'SSS_5MutuallyExclusive.txt'\n",
    "file2 = 'SSS_3MutuallyExclusive.txt'\n",
    "combined_file = 'SSS_MutuallyExclusive.txt'\n",
    "\n",
    "# Open the files in read mode\n",
    "with open(file1, 'r') as f1, open(file2, 'r') as f2:\n",
    "    # Read the contents of the files\n",
    "    file1_contents = f1.readlines()\n",
    "    file2_contents = f2.readlines()\n",
    "\n",
    "# Open the combined file in write mode\n",
    "with open(combined_file, 'w') as f_combined:\n",
    "    # Write the contents of the first file\n",
    "    f_combined.writelines(file1_contents)\n",
    "    # Write the contents of the second file\n",
    "    f_combined.writelines(file2_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  intron retention alternative splicing.\n",
    "\n",
    "unique_genes = pd.read_csv('IntronRetention_Genes.txt', header=None, names=['GeneID'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#extracting the 5 prime splice sites sequences \n",
    "all_5_prime_sequences = []\n",
    "\n",
    "for gene_id in unique_genes['GeneID']:\n",
    "    try:\n",
    "        sequences = extract_5_prime_sequences(gene_id)\n",
    "        all_5_prime_sequences.extend(sequences)  # Only add the sequences\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {gene_id}: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "# Convert to DataFrame\n",
    "sequences_df = pd.DataFrame(all_5_prime_sequences, columns=['sequence'])\n",
    "\n",
    "# Save to TXT\n",
    "sequences_df.to_csv('5_prime_IntronRetention.txt', index=False, sep='\\t')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#extracting the 3 prime splice sites sequences\n",
    "all_3_prime_sequences = []\n",
    "\n",
    "for gene_id in unique_genes['GeneID']:\n",
    "    try:\n",
    "        sequences = extract_3_prime_sequences(gene_id)\n",
    "        all_3_prime_sequences.extend(sequences)  # Only add the sequences\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {gene_id}: {e}\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "sequences_df = pd.DataFrame(all_3_prime_sequences, columns=['sequence'])\n",
    "\n",
    "# Save to TXT\n",
    "sequences_df.to_csv('3_prime_IntronRetention.txt', index=False, sep='\\t')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# The 3' and 5' splice site sequences are analyzed for splice site strength using the following two websites.\n",
    "# http://hollywood.mit.edu/burgelab/maxent/Xmaxentscan_scoreseq.html\n",
    "# http://hollywood.mit.edu/burgelab/maxent/Xmaxentscan_scoreseq_acc.html\n",
    "# the results are saved in 3_prime_IntronRetention.txt and 5_prime_IntronRetention.txt\n",
    "# We extract the values from both files, and then we combine them into one file \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the prime 5 file content\n",
    "with open('5_prime_IntronRetention.txt', 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Use regular expression to find all MAXENT values\n",
    "pattern = r'MAXENT:\\s*(-?\\d*\\.?\\d+)'\n",
    "\n",
    "values = re.findall(pattern, content)\n",
    "\n",
    "\n",
    "# Convert values to float \n",
    "values = [float(value) for value in values]\n",
    "\n",
    "with open('SSS_5IntronRetention.txt', 'w') as output_file:\n",
    "    for value in values:\n",
    "        output_file.write(f'{value}\\n')\n",
    "\n",
    "\n",
    "# Read the prime 3 file content\n",
    "with open('3_prime_IntronRetention.txt', 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Use regular expression to find all MAXENT values\n",
    "pattern = r'MAXENT:\\s*(-?\\d*\\.?\\d+)'\n",
    "\n",
    "values = re.findall(pattern, content)\n",
    "\n",
    "\n",
    "# Convert values to float \n",
    "values = [float(value) for value in values]\n",
    "\n",
    "with open('SSS_3IntronRetention.txt', 'w') as output_file:\n",
    "    for value in values:\n",
    "        output_file.write(f'{value}\\n')\n",
    "\n",
    "\n",
    "\n",
    "# combine the two files\n",
    "file1 = 'SSS_5IntronRetention.txt'\n",
    "file2 = 'SSS_3IntronRetention.txt'\n",
    "combined_file = 'SSS_IntronRetention.txt'\n",
    "\n",
    "# Open the files in read mode\n",
    "with open(file1, 'r') as f1, open(file2, 'r') as f2:\n",
    "    # Read the contents of the files\n",
    "    file1_contents = f1.readlines()\n",
    "    file2_contents = f2.readlines()\n",
    "\n",
    "# Open the combined file in write mode\n",
    "with open(combined_file, 'w') as f_combined:\n",
    "    # Write the contents of the first file\n",
    "    f_combined.writelines(file1_contents)\n",
    "    # Write the contents of the second file\n",
    "    f_combined.writelines(file2_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3' and 5' alternative splicing.\n",
    "\n",
    "unique_genes = pd.read_csv('3_5_PrimeGenes.txt', header=None, names=['GeneID'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#extracting the 5 prime splice sites sequences \n",
    "all_5_prime_sequences = []\n",
    "\n",
    "for gene_id in unique_genes['GeneID']:\n",
    "    try:\n",
    "        sequences = extract_5_prime_sequences(gene_id)\n",
    "        all_5_prime_sequences.extend(sequences)  # Only add the sequences\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {gene_id}: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "# Convert to DataFrame\n",
    "sequences_df = pd.DataFrame(all_5_prime_sequences, columns=['sequence'])\n",
    "\n",
    "# Save to TXT\n",
    "sequences_df.to_csv('5_prime_3_5_Prime.txt', index=False, sep='\\t')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#extracting the 3 prime splice sites sequences\n",
    "all_3_prime_sequences = []\n",
    "\n",
    "for gene_id in unique_genes['GeneID']:\n",
    "    try:\n",
    "        sequences = extract_3_prime_sequences(gene_id)\n",
    "        all_3_prime_sequences.extend(sequences)  # Only add the sequences\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {gene_id}: {e}\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "sequences_df = pd.DataFrame(all_3_prime_sequences, columns=['sequence'])\n",
    "\n",
    "# Save to TXT\n",
    "sequences_df.to_csv('3_prime_3_5_Prime.txt', index=False, sep='\\t')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# The 3' and 5' splice site sequences are analyzed for splice site strength using the following two websites.\n",
    "# http://hollywood.mit.edu/burgelab/maxent/Xmaxentscan_scoreseq.html\n",
    "# http://hollywood.mit.edu/burgelab/maxent/Xmaxentscan_scoreseq_acc.html\n",
    "# the results are saved in 5_prime_3_5_Prime.txt and 3_prime_3_5_Prime.txt\n",
    "# We extract the values from both files, and then we combine them into one file \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the prime 5 file content\n",
    "with open('5_prime_3_5_Prime.txt', 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Use regular expression to find all MAXENT values\n",
    "pattern = r'MAXENT:\\s*(-?\\d*\\.?\\d+)'\n",
    "\n",
    "values = re.findall(pattern, content)\n",
    "\n",
    "\n",
    "# Convert values to float \n",
    "values = [float(value) for value in values]\n",
    "\n",
    "with open('SSS_5_3_5_Prime.txt', 'w') as output_file:\n",
    "    for value in values:\n",
    "        output_file.write(f'{value}\\n')\n",
    "\n",
    "\n",
    "# Read the prime 3 file content\n",
    "with open('3_prime_3_5_Prime.txt', 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Use regular expression to find all MAXENT values\n",
    "pattern = r'MAXENT:\\s*(-?\\d*\\.?\\d+)'\n",
    "\n",
    "values = re.findall(pattern, content)\n",
    "\n",
    "\n",
    "# Convert values to float \n",
    "values = [float(value) for value in values]\n",
    "\n",
    "with open('SSS_3_3_5_Prime.txt', 'w') as output_file:\n",
    "    for value in values:\n",
    "        output_file.write(f'{value}\\n')\n",
    "\n",
    "\n",
    "\n",
    "# combine the two files\n",
    "file1 = 'SSS_5_3_5_Prime.txt'\n",
    "file2 = 'SSS_3_3_5_Prime.txt'\n",
    "combined_file = 'SSS_3_5_Prime.txt'\n",
    "\n",
    "# Open the files in read mode\n",
    "with open(file1, 'r') as f1, open(file2, 'r') as f2:\n",
    "    # Read the contents of the files\n",
    "    file1_contents = f1.readlines()\n",
    "    file2_contents = f2.readlines()\n",
    "\n",
    "# Open the combined file in write mode\n",
    "with open(combined_file, 'w') as f_combined:\n",
    "    # Write the contents of the first file\n",
    "    f_combined.writelines(file1_contents)\n",
    "    # Write the contents of the second file\n",
    "    f_combined.writelines(file2_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we calculate the splice sites strength based on the different datasets of cell lines \n",
    "# Datasets are AU565, BULK_MCF, Ito, MCF7, and MCF10.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AU565 dataset\n",
    "\n",
    "unique_genes = pd.read_csv('AU565_Genes.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#extracting the 5 prime splice sites sequences \n",
    "all_5_prime_sequences = []\n",
    "\n",
    "for gene_id in unique_genes['GeneID']:\n",
    "    try:\n",
    "        sequences = extract_5_prime_sequences(gene_id)\n",
    "        all_5_prime_sequences.extend(sequences)  # Only add the sequences\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {gene_id}: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "# Convert to DataFrame\n",
    "sequences_df = pd.DataFrame(all_5_prime_sequences, columns=['sequence'])\n",
    "\n",
    "# Save to TXT\n",
    "sequences_df.to_csv('5_prime_AU565.txt', index=False, sep='\\t')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#extracting the 3 prime splice sites sequences\n",
    "all_3_prime_sequences = []\n",
    "\n",
    "for gene_id in unique_genes['GeneID']:\n",
    "    try:\n",
    "        sequences = extract_3_prime_sequences(gene_id)\n",
    "        all_3_prime_sequences.extend(sequences)  # Only add the sequences\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {gene_id}: {e}\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "sequences_df = pd.DataFrame(all_3_prime_sequences, columns=['sequence'])\n",
    "\n",
    "# Save to TXT\n",
    "sequences_df.to_csv('3_prime_AU565.txt', index=False, sep='\\t')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# The 3' and 5' splice site sequences are analyzed for splice site strength using the following two websites.\n",
    "# http://hollywood.mit.edu/burgelab/maxent/Xmaxentscan_scoreseq.html\n",
    "# http://hollywood.mit.edu/burgelab/maxent/Xmaxentscan_scoreseq_acc.html\n",
    "# the results are saved in 5_prime_AU565.txt and 3_prime_AU565.txt\n",
    "# We extract the values from both files, and then we combine them into one file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the prime 5 file content\n",
    "with open('5_prime_AU565.txt', 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Use regular expression to find all MAXENT values\n",
    "pattern = r'MAXENT:\\s*(-?\\d*\\.?\\d+)'\n",
    "\n",
    "values = re.findall(pattern, content)\n",
    "\n",
    "\n",
    "# Convert values to float \n",
    "values = [float(value) for value in values]\n",
    "\n",
    "with open('SSS_5_AU565.txt', 'w') as output_file:\n",
    "    for value in values:\n",
    "        output_file.write(f'{value}\\n')\n",
    "\n",
    "\n",
    "# Read the prime 3 file content\n",
    "with open('3_prime_AU565.txt', 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Use regular expression to find all MAXENT values\n",
    "pattern = r'MAXENT:\\s*(-?\\d*\\.?\\d+)'\n",
    "\n",
    "values = re.findall(pattern, content)\n",
    "\n",
    "\n",
    "# Convert values to float \n",
    "values = [float(value) for value in values]\n",
    "\n",
    "with open('SSS_3_AU565.txt', 'w') as output_file:\n",
    "    for value in values:\n",
    "        output_file.write(f'{value}\\n')\n",
    "\n",
    "\n",
    "\n",
    "# combine the two files\n",
    "file1 = 'SSS_5_AU565.txt'\n",
    "file2 = 'SSS_3_AU565.txt'\n",
    "combined_file = 'SSS_AU565.txt'\n",
    "\n",
    "# Open the files in read mode\n",
    "with open(file1, 'r') as f1, open(file2, 'r') as f2:\n",
    "    # Read the contents of the files\n",
    "    file1_contents = f1.readlines()\n",
    "    file2_contents = f2.readlines()\n",
    "\n",
    "# Open the combined file in write mode\n",
    "with open(combined_file, 'w') as f_combined:\n",
    "    # Write the contents of the first file\n",
    "    f_combined.writelines(file1_contents)\n",
    "    # Write the contents of the second file\n",
    "    f_combined.writelines(file2_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BULK_MCF dataset\n",
    "\n",
    "unique_genes = pd.read_csv('BULK_MCF_Genes.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#extracting the 5 prime splice sites sequences \n",
    "all_5_prime_sequences = []\n",
    "\n",
    "for gene_id in unique_genes['GeneID']:\n",
    "    try:\n",
    "        sequences = extract_5_prime_sequences(gene_id)\n",
    "        all_5_prime_sequences.extend(sequences)  # Only add the sequences\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {gene_id}: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "# Convert to DataFrame\n",
    "sequences_df = pd.DataFrame(all_5_prime_sequences, columns=['sequence'])\n",
    "\n",
    "# Save to TXT\n",
    "sequences_df.to_csv('5_prime_BULK_MCF.txt', index=False, sep='\\t')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#extracting the 3 prime splice sites sequences\n",
    "all_3_prime_sequences = []\n",
    "\n",
    "for gene_id in unique_genes['GeneID']:\n",
    "    try:\n",
    "        sequences = extract_3_prime_sequences(gene_id)\n",
    "        all_3_prime_sequences.extend(sequences)  # Only add the sequences\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {gene_id}: {e}\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "sequences_df = pd.DataFrame(all_3_prime_sequences, columns=['sequence'])\n",
    "\n",
    "# Save to TXT\n",
    "sequences_df.to_csv('3_prime_BULK_MCF.txt', index=False, sep='\\t')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# The 3' and 5' splice site sequences are analyzed for splice site strength using the following two websites.\n",
    "# http://hollywood.mit.edu/burgelab/maxent/Xmaxentscan_scoreseq.html\n",
    "# http://hollywood.mit.edu/burgelab/maxent/Xmaxentscan_scoreseq_acc.html\n",
    "# the results are saved in 5_prime_BULK_MCF.txt and 3_prime_BULK_MCF.txt\n",
    "# We extract the values from both files, and then we combine them into one file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the prime 5 file content\n",
    "with open('5_prime_BULK_MCF.txt', 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Use regular expression to find all MAXENT values\n",
    "pattern = r'MAXENT:\\s*(-?\\d*\\.?\\d+)'\n",
    "\n",
    "values = re.findall(pattern, content)\n",
    "\n",
    "\n",
    "# Convert values to float \n",
    "values = [float(value) for value in values]\n",
    "\n",
    "with open('SSS_5_BULK_MCF.txt', 'w') as output_file:\n",
    "    for value in values:\n",
    "        output_file.write(f'{value}\\n')\n",
    "\n",
    "\n",
    "# Read the prime 3 file content\n",
    "with open('3_prime_BULK_MCF.txt', 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Use regular expression to find all MAXENT values\n",
    "pattern = r'MAXENT:\\s*(-?\\d*\\.?\\d+)'\n",
    "\n",
    "values = re.findall(pattern, content)\n",
    "\n",
    "\n",
    "# Convert values to float \n",
    "values = [float(value) for value in values]\n",
    "\n",
    "with open('SSS_3_BULK_MCF.txt', 'w') as output_file:\n",
    "    for value in values:\n",
    "        output_file.write(f'{value}\\n')\n",
    "\n",
    "\n",
    "\n",
    "# combine the two files\n",
    "file1 = 'SSS_5_BULK_MCF.txt'\n",
    "file2 = 'SSS_3_BULK_MCF.txt'\n",
    "combined_file = 'SSS_BULK_MCF.txt'\n",
    "\n",
    "# Open the files in read mode\n",
    "with open(file1, 'r') as f1, open(file2, 'r') as f2:\n",
    "    # Read the contents of the files\n",
    "    file1_contents = f1.readlines()\n",
    "    file2_contents = f2.readlines()\n",
    "\n",
    "# Open the combined file in write mode\n",
    "with open(combined_file, 'w') as f_combined:\n",
    "    # Write the contents of the first file\n",
    "    f_combined.writelines(file1_contents)\n",
    "    # Write the contents of the second file\n",
    "    f_combined.writelines(file2_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ito dataset\n",
    "\n",
    "unique_genes = pd.read_csv('Ito_Genes.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#extracting the 5 prime splice sites sequences \n",
    "all_5_prime_sequences = []\n",
    "\n",
    "for gene_id in unique_genes['GeneID']:\n",
    "    try:\n",
    "        sequences = extract_5_prime_sequences(gene_id)\n",
    "        all_5_prime_sequences.extend(sequences)  # Only add the sequences\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {gene_id}: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "# Convert to DataFrame\n",
    "sequences_df = pd.DataFrame(all_5_prime_sequences, columns=['sequence'])\n",
    "\n",
    "# Save to TXT\n",
    "sequences_df.to_csv('5_prime_Ito.txt', index=False, sep='\\t')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#extracting the 3 prime splice sites sequences\n",
    "all_3_prime_sequences = []\n",
    "\n",
    "for gene_id in unique_genes['GeneID']:\n",
    "    try:\n",
    "        sequences = extract_3_prime_sequences(gene_id)\n",
    "        all_3_prime_sequences.extend(sequences)  # Only add the sequences\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {gene_id}: {e}\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "sequences_df = pd.DataFrame(all_3_prime_sequences, columns=['sequence'])\n",
    "\n",
    "# Save to TXT\n",
    "sequences_df.to_csv('3_prime_Ito.txt', index=False, sep='\\t')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# The 3' and 5' splice site sequences are analyzed for splice site strength using the following two websites.\n",
    "# http://hollywood.mit.edu/burgelab/maxent/Xmaxentscan_scoreseq.html\n",
    "# http://hollywood.mit.edu/burgelab/maxent/Xmaxentscan_scoreseq_acc.html\n",
    "# the results are saved in 5_prime_Ito.txt and 3_prime_Ito.txt\n",
    "# We extract the values from both files, and then we combine them into one file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the prime 5 file content\n",
    "with open('5_prime_Ito.txt', 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Use regular expression to find all MAXENT values\n",
    "pattern = r'MAXENT:\\s*(-?\\d*\\.?\\d+)'\n",
    "\n",
    "values = re.findall(pattern, content)\n",
    "\n",
    "\n",
    "# Convert values to float \n",
    "values = [float(value) for value in values]\n",
    "\n",
    "with open('SSS_5_Ito.txt', 'w') as output_file:\n",
    "    for value in values:\n",
    "        output_file.write(f'{value}\\n')\n",
    "\n",
    "\n",
    "# Read the prime 3 file content\n",
    "with open('3_prime_Ito.txt', 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Use regular expression to find all MAXENT values\n",
    "pattern = r'MAXENT:\\s*(-?\\d*\\.?\\d+)'\n",
    "\n",
    "values = re.findall(pattern, content)\n",
    "\n",
    "\n",
    "# Convert values to float \n",
    "values = [float(value) for value in values]\n",
    "\n",
    "with open('SSS_3_Ito.txt', 'w') as output_file:\n",
    "    for value in values:\n",
    "        output_file.write(f'{value}\\n')\n",
    "\n",
    "\n",
    "\n",
    "# combine the two files\n",
    "file1 = 'SSS_5_Ito.txt'\n",
    "file2 = 'SSS_3_Ito.txt'\n",
    "combined_file = 'SSS_Ito.txt'\n",
    "\n",
    "# Open the files in read mode\n",
    "with open(file1, 'r') as f1, open(file2, 'r') as f2:\n",
    "    # Read the contents of the files\n",
    "    file1_contents = f1.readlines()\n",
    "    file2_contents = f2.readlines()\n",
    "\n",
    "# Open the combined file in write mode\n",
    "with open(combined_file, 'w') as f_combined:\n",
    "    # Write the contents of the first file\n",
    "    f_combined.writelines(file1_contents)\n",
    "    # Write the contents of the second file\n",
    "    f_combined.writelines(file2_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MCF7 dataset\n",
    "\n",
    "unique_genes = pd.read_csv('MCF7_Genes.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#extracting the 5 prime splice sites sequences \n",
    "all_5_prime_sequences = []\n",
    "\n",
    "for gene_id in unique_genes['GeneID']:\n",
    "    try:\n",
    "        sequences = extract_5_prime_sequences(gene_id)\n",
    "        all_5_prime_sequences.extend(sequences)  # Only add the sequences\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {gene_id}: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "# Convert to DataFrame\n",
    "sequences_df = pd.DataFrame(all_5_prime_sequences, columns=['sequence'])\n",
    "\n",
    "# Save to TXT\n",
    "sequences_df.to_csv('5_prime_MCF7.txt', index=False, sep='\\t')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#extracting the 3 prime splice sites sequences\n",
    "all_3_prime_sequences = []\n",
    "\n",
    "for gene_id in unique_genes['GeneID']:\n",
    "    try:\n",
    "        sequences = extract_3_prime_sequences(gene_id)\n",
    "        all_3_prime_sequences.extend(sequences)  # Only add the sequences\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {gene_id}: {e}\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "sequences_df = pd.DataFrame(all_3_prime_sequences, columns=['sequence'])\n",
    "\n",
    "# Save to TXT\n",
    "sequences_df.to_csv('3_prime_MCF7.txt', index=False, sep='\\t')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# The 3' and 5' splice site sequences are analyzed for splice site strength using the following two websites.\n",
    "# http://hollywood.mit.edu/burgelab/maxent/Xmaxentscan_scoreseq.html\n",
    "# http://hollywood.mit.edu/burgelab/maxent/Xmaxentscan_scoreseq_acc.html\n",
    "# the results are saved in 5_prime_MCF7.txt and 3_prime_MCF7.txt\n",
    "# We extract the values from both files, and then we combine them into one file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the prime 5 file content\n",
    "with open('5_prime_MCF7.txt', 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Use regular expression to find all MAXENT values\n",
    "pattern = r'MAXENT:\\s*(-?\\d*\\.?\\d+)'\n",
    "\n",
    "values = re.findall(pattern, content)\n",
    "\n",
    "\n",
    "# Convert values to float \n",
    "values = [float(value) for value in values]\n",
    "\n",
    "with open('SSS_5_MCF7.txt', 'w') as output_file:\n",
    "    for value in values:\n",
    "        output_file.write(f'{value}\\n')\n",
    "\n",
    "\n",
    "# Read the prime 3 file content\n",
    "with open('3_prime_MCF7.txt', 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Use regular expression to find all MAXENT values\n",
    "pattern = r'MAXENT:\\s*(-?\\d*\\.?\\d+)'\n",
    "\n",
    "values = re.findall(pattern, content)\n",
    "\n",
    "\n",
    "# Convert values to float \n",
    "values = [float(value) for value in values]\n",
    "\n",
    "with open('SSS_3_MCF7.txt', 'w') as output_file:\n",
    "    for value in values:\n",
    "        output_file.write(f'{value}\\n')\n",
    "\n",
    "\n",
    "\n",
    "# combine the two files\n",
    "file1 = 'SSS_5_MCF7.txt'\n",
    "file2 = 'SSS_3_MCF7.txt'\n",
    "combined_file = 'SSS_MCF7.txt'\n",
    "\n",
    "# Open the files in read mode\n",
    "with open(file1, 'r') as f1, open(file2, 'r') as f2:\n",
    "    # Read the contents of the files\n",
    "    file1_contents = f1.readlines()\n",
    "    file2_contents = f2.readlines()\n",
    "\n",
    "# Open the combined file in write mode\n",
    "with open(combined_file, 'w') as f_combined:\n",
    "    # Write the contents of the first file\n",
    "    f_combined.writelines(file1_contents)\n",
    "    # Write the contents of the second file\n",
    "    f_combined.writelines(file2_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MCF10 dataset\n",
    "\n",
    "unique_genes = pd.read_csv('MCF10_Genes.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#extracting the 5 prime splice sites sequences \n",
    "all_5_prime_sequences = []\n",
    "\n",
    "for gene_id in unique_genes['GeneID']:\n",
    "    try:\n",
    "        sequences = extract_5_prime_sequences(gene_id)\n",
    "        all_5_prime_sequences.extend(sequences)  # Only add the sequences\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {gene_id}: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "# Convert to DataFrame\n",
    "sequences_df = pd.DataFrame(all_5_prime_sequences, columns=['sequence'])\n",
    "\n",
    "# Save to TXT\n",
    "sequences_df.to_csv('5_prime_MCF10.txt', index=False, sep='\\t')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#extracting the 3 prime splice sites sequences\n",
    "all_3_prime_sequences = []\n",
    "\n",
    "for gene_id in unique_genes['GeneID']:\n",
    "    try:\n",
    "        sequences = extract_3_prime_sequences(gene_id)\n",
    "        all_3_prime_sequences.extend(sequences)  # Only add the sequences\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {gene_id}: {e}\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "sequences_df = pd.DataFrame(all_3_prime_sequences, columns=['sequence'])\n",
    "\n",
    "# Save to TXT\n",
    "sequences_df.to_csv('3_prime_MCF10.txt', index=False, sep='\\t')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# The 3' and 5' splice site sequences are analyzed for splice site strength using the following two websites.\n",
    "# http://hollywood.mit.edu/burgelab/maxent/Xmaxentscan_scoreseq.html\n",
    "# http://hollywood.mit.edu/burgelab/maxent/Xmaxentscan_scoreseq_acc.html\n",
    "# the results are saved in 5_prime_MCF10.txt and 3_prime_MCF10.txt\n",
    "# We extract the values from both files, and then we combine them into one file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the prime 5 file content\n",
    "with open('5_prime_MCF10.txt', 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Use regular expression to find all MAXENT values\n",
    "pattern = r'MAXENT:\\s*(-?\\d*\\.?\\d+)'\n",
    "\n",
    "values = re.findall(pattern, content)\n",
    "\n",
    "\n",
    "# Convert values to float \n",
    "values = [float(value) for value in values]\n",
    "\n",
    "with open('SSS_5_MCF10.txt', 'w') as output_file:\n",
    "    for value in values:\n",
    "        output_file.write(f'{value}\\n')\n",
    "\n",
    "\n",
    "# Read the prime 3 file content\n",
    "with open('3_prime_MCF10.txt', 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Use regular expression to find all MAXENT values\n",
    "pattern = r'MAXENT:\\s*(-?\\d*\\.?\\d+)'\n",
    "\n",
    "values = re.findall(pattern, content)\n",
    "\n",
    "\n",
    "# Convert values to float \n",
    "values = [float(value) for value in values]\n",
    "\n",
    "with open('SSS_3_MCF10.txt', 'w') as output_file:\n",
    "    for value in values:\n",
    "        output_file.write(f'{value}\\n')\n",
    "\n",
    "\n",
    "\n",
    "# combine the two files\n",
    "file1 = 'SSS_5_MCF10.txt'\n",
    "file2 = 'SSS_3_MCF10.txt'\n",
    "combined_file = 'SSS_MCF10.txt'\n",
    "\n",
    "# Open the files in read mode\n",
    "with open(file1, 'r') as f1, open(file2, 'r') as f2:\n",
    "    # Read the contents of the files\n",
    "    file1_contents = f1.readlines()\n",
    "    file2_contents = f2.readlines()\n",
    "\n",
    "# Open the combined file in write mode\n",
    "with open(combined_file, 'w') as f_combined:\n",
    "    # Write the contents of the first file\n",
    "    f_combined.writelines(file1_contents)\n",
    "    # Write the contents of the second file\n",
    "    f_combined.writelines(file2_contents)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
